# Agent Orchestration Pattern
# Multi-agent coordination and orchestrator-worker pattern

version: "1.0"
category: "agent-workflow"
last_updated: "2026-01-07"

patterns:
  - id: "AGENT-ORCHESTRATION-001"
    title: "Multi-Agent Orchestration with Orchestrator-Worker Pattern"
    severity: "high"
    scope: "universal"
    tags: ["agents", "orchestration", "multi-agent", "coordination", "parallel", "workflow"]

    problem: |
      Complex AI tasks require:
      - Multiple specialized capabilities (security, architecture, testing, documentation)
      - Parallel execution to complete faster
      - Coordination between different specialists
      - State management across the workflow
      - Error handling and recovery

      **Without orchestration:**
      - Sequential execution (slow)
      - Context pollution between tasks
      - No specialization (one agent does everything)
      - Difficult to track progress
      - Poor error recovery

    impact: |
      - **Speed:** 3-5x faster with parallel agents
      - **Quality:** Specialized agents produce better output
      - **Maintainability:** Clear separation of concerns
      - **Scalability:** Easy to add/remove agents
      - **Cost:** 70% cheaper by using right model per task

    solution: |
      **Orchestrator-Worker Pattern:**

      Use a main orchestrator agent that:
      1. Understands the overall request
      2. Breaks it into subtasks
      3. Spawns specialized subagents
      4. Coordinates execution (parallel when possible)
      5. Aggregates and validates results
      6. Handles errors and retries

    implementation: "@references/AGENT-ORCHESTRATION-001-implementation.md"

    best_practices:
      - practice: "Use parallel execution when possible"
        guideline: "Identify independent tasks that can run simultaneously"
        example: "Security + Architecture agents in Phase 1"
        benefit: "3-5x faster completion"

      - practice: "Match model to task complexity"
        guideline: |
          Opus 4: Planning, orchestration, complex reasoning
          Sonnet 4: Coding, analysis, specialized work
          Haiku 4: Routine tasks, documentation
        benefit: "70% cost savings while maintaining quality"

      - practice: "Maintain clear agent boundaries"
        guideline: "Each agent has one clear domain. No overlap."
        example: "Security Agent: Only security. Architecture Agent: Only design."
        benefit: "No duplicated work, clear responsibilities"

      - practice: "Use hooks for deterministic validation"
        guideline: "Don't trust agent self-check. Use hooks for automatic validation."
        example: "pre-commit hook: Run tests, check coverage, lint"
        benefit: "Quality gates, no false positives"

      - practice: "Implement proper error recovery"
        guideline: "Don't fail entire workflow on single agent failure"
        example: "Re-run agent with feedback, or escalate to human"
        benefit: "Resilient system, graceful degradation"

      - practice: "Track everything in state"
        guideline: "Maintain global state of all agents, decisions, progress"
        example: "state.json with status of all agents"
        benefit: "Auditability, debugging, resumption"

      - practice: "Use right tool permissions per agent"
        guideline: "Each agent only gets tools needed for its domain"
        example: "Security Agent: [read, grep, report] (no write!)"
        benefit: "Security, risk mitigation"

    anti_patterns:
      - pattern: "Too much autonomy"
        wrong: "Here's the codebase. Build the whole system."
        consequence: "Agent gets lost, makes conflicting decisions, low quality"
        correct: |
          "Build authentication system with constraints:
           1. Use JWT tokens
           2. Passwords hashed with bcrypt
           3. Tests must pass before commit
           4. Get approval before merging"

      - pattern: "Wrong model for task"
        wrong: "Use Haiku 4 for complex architectural planning"
        consequence: "Fails to understand nuances, poor decisions"
        correct: |
          Opus 4: Planning, orchestration
          Sonnet 4: Coding, specialized work
          Haiku 4: Routine tasks

      - pattern: "Context overflow in orchestrator"
        wrong: "Orchestrator maintains ALL details of all subagents"
        consequence: "Context overflow, quality degrades"
        correct: |
          Orchestrator maintains ONLY:
          - Completed: Phase 1 (spec.md)
          - In Progress: Phase 2 (implementation)
          - Pending: Phase 3 (testing)
          Each subagent manages their own context

      - pattern: "No validation gates"
        wrong: "Trust agent self-check: 'Does this look correct?'"
        consequence: "Agent says yes but it's wrong. No external validation."
        correct: |
          Use hooks for automatic validation:
          - Run tests (must pass)
          - Check coverage (≥80%)
          - Run linter (0 errors)
          - Security scan (0 critical issues)

      - pattern: "Unclear agent boundaries"
        wrong: "Do whatever you think is best"
        consequence: "Overlap, duplicated work, conflicting implementations"
        correct: |
          - Security Agent: Only security decisions
          - Architecture Agent: Only design decisions
          - Implementation Agent: Only coding
          Clear boundaries, clear handoffs

    real_world_examples:
      example_1_oauth2_implementation:
        scenario: "Implement OAuth2 login feature"

        team:
          - "Orchestrator Agent (Opus 4): Planning & coordination"
          - "Security Agent (Sonnet 4): OAuth2 flow design"
          - "Architecture Agent (Sonnet 4): User schema design"
          - "Implementation Agent (Sonnet 4): API coding"
          - "Testing Agent (Sonnet 4): Test generation"
          - "Documentation Agent (Haiku 4): Docs & examples"

        workflow:
          phase_1_parallel_design:
            tasks:
              - "Security Agent (2h): OAuth2 flow review"
              - "Architecture Agent (2h): User schema design"
            total_time: "2h (parallel)"

          phase_2_implementation:
            tasks:
              - "Implementation Agent (4h): Code auth endpoints"
            depends_on: "security-design.md + user-schema.sql"
            total_time: "4h"

          phase_3_parallel_testing_docs:
            tasks:
              - "Testing Agent (3h): Test suite (85% coverage)"
              - "Documentation Agent (2h): README + API docs"
            total_time: "3h (parallel)"

        results:
          total_time: "9 hours (2 + 4 + 3)"
          vs_single_agent: "~40 hours (sequential)"
          speed_improvement: "4.4x faster"
          cost: "$37 (mixed models) vs $4000 (40h @ $100/h)"
          cost_savings: "100x cheaper"

      example_2_parallel_code_review:
        scenario: "Automated PR review system"

        agents:
          - "PR Watcher: Detects new PRs, triggers workflow"
          - "Style Reviewer: Linting, naming, patterns"
          - "Security Reviewer: SQLi, XSS, auth issues"
          - "Performance Reviewer: N+1, bundles, loops"
          - "Architecture Reviewer: Design patterns, separation"
          - "Aggregator: Combines all reviews, posts comment"

        workflow:
          trigger: "GitHub webhook → PR created"
          parallel_review: "4 reviewers work simultaneously (5 min)"
          aggregation: "Aggregator combines feedback (1 min)"
          posting: "Posts comprehensive review as single comment"

        results:
          review_time: "6 minutes total"
          vs_human: "~2 hours (human reviewer)"
          coverage: "All domains checked, nothing missed"
          consistency: "Same standards every time"

      example_3_security_audit_parallel:
        scenario: "Comprehensive security audit of codebase"

        agents:
          - "SQL Injection Agent: Grep for SQL patterns"
          - "XSS Agent: Grep for innerHTML, eval"
          - "Secrets Agent: Grep for passwords, API keys"
          - "Dependencies Agent: Check outdated packages"
          - "Config Agent: Check insecure configurations"
          - "Report Aggregator: Compile findings"

        workflow:
          parallel_search: "5 agents search simultaneously (2 min)"
          analysis: "Each agent analyzes their findings (3 min)"
          aggregation: "Aggregator compiles security report (2 min)"

        results:
          total_time: "7 minutes"
          vs_manual: "~4 hours (manual audit)"
          coverage: "5 agents = 5x coverage"
          consistency: "No human fatigue, thorough every time"

    file_structure:
      recommended_layout: |
        .claude/
        ├── agents/
        │   ├── orchestrator.md          ← Main orchestrator config
        │   │   ├── description: "Delegates tasks"
        │   │   ├── model: "claude-opus-4"
        │   │   └── tools: [read, route]
        │   │
        │   ├── code-review-agent.md     ← Specialist agent
        │   │   ├── description: "Reviews code"
        │   │   ├── model: "claude-sonnet-4"
        │   │   └── tools: [grep, read, comment]
        │   │
        │   ├── security-agent.md        ← Specialist agent
        │   │   ├── description: "Audits security"
        │   │   ├── model: "claude-sonnet-4"
        │   │   └── tools: [grep, read, report]
        │   │
        │   └── state.json               ← Global state
        │       ├── current_task
        │       ├── completed_subtasks
        │       ├── pending_work
        │       └── decisions
        │
        ├── skills/                       ← Skills (called by agents)
        │   ├── testing/
        │   ├── documentation/
        │   └── refactoring/
        │
        ├── hooks/                        ← Lifecycle hooks
        │   ├── post-agent-run.sh        ← After agent completes
        │   └── error-recovery.sh        ← On agent failure
        │
        └── mcp/                          ← External integrations
            ├── github.server
            ├── jira.server
            └── slack.server

    testing:
      unit_tests: |
        Test each agent independently:
        - Mock external systems
        - Verify agent produces correct output
        - Example: "Security agent detects SQL injection"

      integration_tests: |
        Test agents working together:
        - Use real (test) systems
        - Verify coordination works
        - Example: "Orchestrator + Agents complete feature"

      end_to_end_tests: |
        Full workflow validation:
        - Production-like environment
        - From request to deployment
        - Example: "Feature request → ready in production"

      evaluation_metrics:
        completeness:
          - "Did agent finish assigned task? Y/N"
          - "Did it produce required output? Y/N"
          - "Is output in correct format? Y/N"

        correctness:
          - "Does output match specification?"
          - "Are there errors or incomplete parts?"
          - "Would this pass code review? Y/N"

        quality:
          - "Readability (can humans understand?)"
          - "Performance (efficient code/queries?)"
          - "Security (safe, no vulnerabilities?)"

        cost:
          - "Tokens used"
          - "Time taken"
          - "API calls made"

    monitoring:
      performance_metrics:
        - "Success rate (%)"
        - "Error rate (%)"
        - "Average completion time"
        - "P95, P99 latency"
        - "Cost per execution"

      quality_metrics:
        - "Output quality score (0-10)"
        - "Rework rate (%)"
        - "User satisfaction (1-5)"
        - "Bug discovery rate"

      alerts:
        - "Error rate spike (>5%)"
        - "Latency spike (>5min)"
        - "Cost anomaly (>2x expected)"
        - "Agent timeout"
        - "MCP connection failure"

    benefits:
      performance:
        - "3-5x faster (parallel execution)"
        - "70% cost savings (right model per task)"
        - "Better quality (specialized agents)"

      maintainability:
        - "Clear separation of concerns"
        - "Easy to add/remove agents"
        - "Independent agent updates"

      reliability:
        - "Resilient to agent failure"
        - "Graceful error recovery"
        - "Deterministic validation"

      scalability:
        - "Add more agents as needed"
        - "Handle complex workflows"
        - "Production-ready deployment"

    prevention:
      - prevention: "Start with orchestrator-worker pattern for complex tasks"
        reason: "Provides clear structure and separation of concerns"
        how: "Use main orchestrator + specialized subagents from project start"

      - prevention: "Define clear agent responsibilities upfront"
        reason: "Prevents overlap and confusion between agents"
        how: "Document each agent's scope, tools, and boundaries"

      - prevention: "Use appropriate model for each agent type"
        reason: "Cost optimization and better results"
        how: "Opus for orchestrator, Sonnet for specialists, Haiku for simple tasks"

      - prevention: "Set reasonable timeouts for subagent tasks"
        reason: "Prevents hanging and infinite loops"
        how: "Configure timeouts based on task complexity (5-30 min typical)"

      - prevention: "Implement state management from the beginning"
        reason: "Essential for tracking progress and handling errors"
        how: "Maintain global state with request status, agent outputs, decisions"

      - prevention: "Test subagent workflows before production"
        reason: "Catches integration issues early"
        how: "Run orchestrator with test tasks, verify all agents complete successfully"

      - prevention: "Provide clear context and success criteria"
        reason: "Ensures agents understand what's expected"
        how: "Include task description, input files, expected output format, deadline"

      - prevention: "Monitor agent performance and optimize"
        reason: "Continuous improvement of orchestration"
        how: "Track task completion times, success rates, error patterns"

    related_patterns:
      - SKILL-DESIGN-001 (Skill design best practices)
      - AGENT-TASK-TRACKING-001 (Task tracking in agents)
      - PROGRESSIVE-DISCLOSURE-001 (Context optimization)
      - MCP-INTEGRATION-001 (External system integration)

    references:
      - "Claude Code Agents Documentation"
      - "Claude Agents Guide: tmp/claude-agents-guide.md (1,251 lines)"
      - "Orchestrator-Worker Pattern"

    metadata:
      created_at: "2026-01-07"
      author: "Shared KB Curator"
      source: "Claude Code Agents Guide analysis"
      reusable: true
      severity_level: 2
      difficulty: "advanced"
      pattern_type: "architecture"
      applicable_to: ["claude-code", "agents", "multi-agent-systems", "orchestration"]
