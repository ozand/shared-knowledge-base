version: "1.0"
category: "postgresql"
last_updated: "2026-01-06"

patterns:
  - id: "pg-perf-001"
title: PostgreSQL 18 Performance Configuration for High-End Servers
category: postgresql
severity: high
tags: [performance, tuning, configuration, postgresql-18, memory]

problem: |
  PostgreSQL default configuration is extremely conservative and suboptimal
  for systems with large amounts of RAM (64GB+). Default settings cause the
  database to operate at only 10-20% of potential capacity.

symptoms:
  - High disk I/O despite having abundant RAM
  - Slow query execution times
  - Low cache hit ratio (< 0.80)
  - Poor parallel query performance
  - Frequent checkpoints causing I/O spikes
  - VACUUM operations taking too long

context:
  applicable_versions: "PostgreSQL 14, 15, 16, 17, 18"
  system_requirements:
    ram: "64GB+ recommended for these settings"
    cpu: "8+ cores recommended"
    storage: "SSD/NVMe recommended"

solution: |
  OPTIMAL CONFIGURATION for 128GB RAM system:

  # PostgreSQL 18 Configuration Tuning
  # Edit postgresql.conf and restart PostgreSQL

  # === MEMORY SETTINGS (Critical) ===
  shared_buffers = 32GB              # 25% of RAM - shared cache
  effective_cache_size = 96GB        # 75% of RAM - OS cache + PG cache hint
  work_mem = 256MB                   # Per operation memory for sort/hash
  maintenance_work_mem = 16GB        # For VACUUM, CREATE INDEX, ALTER TABLE
  autovacuum_work_mem = 8GB          # Dedicated memory for autovacuum

  # === PARALLELISM (Critical) ===
  max_worker_processes = 32          # Total background workers (all CPU cores)
  max_parallel_workers = 32          # Max workers for parallel operations
  max_parallel_workers_per_gather = 8  # Parallel workers per query
  max_parallel_maintenance_workers = 8  # Parallel workers for maintenance
  parallel_leader_participation = on # Leader process participates too

  # === WAL TUNING (Important) ===
  max_wal_size = 16GB                # Max WAL size before checkpoint
  min_wal_size = 2GB                 # Min WAL size to maintain
  checkpoint_timeout = 15min         # Time between checkpoints
  checkpoint_completion_target = 0.9 # Checkpoint spread target
  wal_compression = zstd             # Compress WAL (PG 17+, zstd is fastest)

  # === QUERY PLANNER ===
  default_statistics_target = 200    # Statistics quality (default: 100)
  random_page_cost = 1.1             # For SSD (default: 4.0 for HDD)
  seq_page_cost = 1.0                # Sequential scan cost

  # === I/O CONCURRENCY (PostgreSQL 18) ===
  effective_io_concurrency = 200     # For SSD/NVMe storage
  maintenance_io_concurrency = 200   # For maintenance operations

  # === AUTOVACUUM ===
  autovacuum_max_workers = 8         # Max parallel autovacuum workers
  autovacuum_naptime = 10s           # Frequency of autovacuum checks
  autovacuum_worker_slots = 16       # Already well-configured

expected_improvements:
  read_performance: "+200-400%"
  write_performance: "+30-50%"
  complex_queries: "+100-300%"
  vacuum_operations: "+200-400%"
  overall_capacity: "+100-200%"
  cache_hit_ratio: "0.95+ (from 0.60-0.80)"

validation: |
  1. Verify settings are loaded:
     SELECT name, setting, unit, source
     FROM pg_settings
     WHERE name IN ('shared_buffers', 'effective_cache_size', 'work_mem',
                    'max_worker_processes', 'max_parallel_workers')
     ORDER BY name;

  2. Check cache hit ratio (should be > 0.95):
     SELECT
       sum(heap_blks_read) as heap_read,
       sum(heap_blks_hit) as heap_hit,
       round(sum(heap_blks_hit)::numeric /
             (sum(heap_blks_hit) + sum(heap_blks_read)), 4) as ratio
     FROM pg_statio_user_tables;

  3. Monitor parallel query execution:
     EXPLAIN (ANALYZE, BUFFERS) <your_large_query>;
     -- Look for "Workers Launched" in execution plan

  4. Check system resource usage:
     -- Windows:
     Get-Counter '\\Processor(_Total)\\% Processor Time'
     Get-Counter '\\Memory\\Available MBytes'
     -- Target: CPU 40-80%, RAM usage 50-70%

rollout_plan:
  phases:
    - phase: "Critical Settings (Week 1)"
      settings:
        - shared_buffers
        - effective_cache_size
        - work_mem
        - max_worker_processes
        - max_parallel_workers
      monitoring: "Check daily for 1 week"

    - phase: "Additional Optimizations (Week 2)"
      settings:
        - maintenance_work_mem
        - max_wal_size
        - wal_compression
        - default_statistics_target
      monitoring: "Check daily for 1 week"

    - phase: "Fine-tuning (Week 3-4)"
      settings:
        - random_page_cost
        - effective_io_concurrency
        - autovacuum settings
      monitoring: "Adjust based on workload"

  rollback_plan: |
    If issues occur:
    1. Stop PostgreSQL service
    2. Restore backup: postgresql.conf.backup_YYYYMMDD.txt
    3. Start PostgreSQL service
    4. Verify with validation queries above

sources:
  - title: "PostgreSQL 18 Documentation - Resource Consumption"
    url: "https://www.postgresql.org/docs/current/runtime-config-resource.html"
  - title: "PostgreSQL Performance Tuning Guide"
    url: "https://wiki.postgresql.org/wiki/Performance_Optimization"
  - title: "PGTune - Online PostgreSQL Configuration Calculator"
    url: "https://pgtune.leopard.in.ua/"
  - title: "PostgreSQL 18: Better I/O Performance with AIO"
    url: "https://www.cybertec-postgresql.com/en/postgresql-18-better-i-o-performance-with-aio/"
  - title: "Internal Analysis Report"
    url: "https://github.com/ozand/shared-knowledge-base/blob/master/postgresql/patterns/performance-tuning.md"

examples:
  - description: "Before and After - Query Performance"
    before:
      query: "SELECT count(*) FROM large_table JOIN another_large_table;"
      execution_time: "5.2s"
      execution_plan: "Seq Scan on large_table (cost=0.00..123456.78 rows=5000000 width=12)"

    after:
      query: "SELECT count(*) FROM large_table JOIN another_large_table;"
      execution_time: "1.8s"
      execution_plan: "Gather (cost=1000.00..56789.12 rows=5000000 width=12)"
      improvement: "65% faster with 4 parallel workers"

  - description: "Before and After - VACUUM Performance"
    before:
      operation: "VACUUM ANALYZE large_table;"
      duration: "45 minutes"
      memory_usage: "64MB (maintenance_work_mem default)"

    after:
      operation: "VACUUM ANALYZE large_table;"
      duration: "8 minutes"
      memory_usage: "16GB (maintenance_work_mem tuned)"
      improvement: "82% faster"

tested:
  system: "Windows Server, PostgreSQL 18.1, AMD Ryzen 9 5950X, 128GB RAM"
  result: |
    - SELECT with index: 1.240ms → 0.770ms (38% faster)
    - RAM usage: 4GB → 50GB (effective caching)
    - Parallel workers: 8 → 32 (full CPU utilization)
    - Maintenance operations: 64MB → 16GB work_mem
  date: "2026-01-04"
  status: "production_ready"

caveats:
  - "Settings optimized for 128GB RAM - adjust proportionally for different sizes"
  - "High work_mem values can cause memory pressure with many concurrent connections"
  - "Parallel workers don't help for small tables (< 8MB per worker)"
  - "Checkpoints become less frequent but longer - ensure I/O capacity"
  - "Always test changes in staging environment first"

related_patterns:
  - id: "pg-migration-001"
    title: "PostgreSQL Major Version Migration with pg_upgrade"
  - id: "pg-vacuum-001"
    title: "VACUUM Tuning for Large Databases"
  - id: "pg-index-001"
    title: "Index Optimization Strategies"

languages: [en, ru]
